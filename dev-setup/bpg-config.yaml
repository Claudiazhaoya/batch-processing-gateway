defaultSparkConf:
  spark.kubernetes.submission.connectionTimeout: 30000
  spark.kubernetes.submission.requestTimeout: 30000
  spark.kubernetes.driver.connectionTimeout: 30000
  spark.kubernetes.driver.requestTimeout: 30000
sparkClusters:
  - weight: 100
    id: minikube
    eksCluster: minikube
    masterUrl: https://127.0.0.1:54638
    caCertDataSOPS: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCakNDQWU2Z0F3SUJBZ0lCQVRBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwdGFXNXAKYTNWaVpVTkJNQjRYRFRJek1ERXdPREU0TXpFeU9Gb1hEVE16TURFd05qRTRNekV5T0Zvd0ZURVRNQkVHQTFVRQpBeE1LYldsdWFXdDFZbVZEUVRDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTTNkClA2OE1uaVVVTTRtamE5V0JpNlkvamhZeWxsZURhNmtsUEFFSGxHaGFoMTJ1WTg2WnUrSHhuNFdkU0xSOXpTOG0KbVFJczBnVzdJSnF4RFU0bFZQZDlCK2cwY3JPQWxGQXlaT1NOdkkxSWFUVFdQR1dkZ3hyWGZzZ051ek9wYXpsTQovU1MxWUpPQ09KbkduZFNxR1BOTSs2RTIvOTFWSWVDcHUyS3lHd0ZIZDlpOGZqcTVGVG9rdEs1ME01aWtHaHJ1CjE0QXhFRGNLbmtwcENoZDlIM2piWUVnWGk4V2w5c0czdGlmalF4b0xmODVvazJ1UDJYV2dZeWdwYlRoVUFvY28KM3pHL3I1NUYrQ1JDcWdFcjk5RVFPKzljRGRxcFRtOEZSQjBUSVFMOGJ5UXRqOHFzOUpvRkcwaXczT3ZlKzZCNQpDb3dEQ1lvazZqdUFJL1RoY2dFQ0F3RUFBYU5oTUY4d0RnWURWUjBQQVFIL0JBUURBZ0trTUIwR0ExVWRKUVFXCk1CUUdDQ3NHQVFVRkJ3TUNCZ2dyQmdFRkJRY0RBVEFQQmdOVkhSTUJBZjhFQlRBREFRSC9NQjBHQTFVZERnUVcKQkJSSEpxd01Cc0laK2ZTbC9wYS90bzk0S3ZNVExEQU5CZ2txaGtpRzl3MEJBUXNGQUFPQ0FRRUFxU1FxR2V4SApOV3ZFeC9hemR3TDhtNFF3ayt2UzYxMkwvN1VRbmNKV0txbGhTQUorOTRxSFNOZlRlL3VHblJPTXNsRlJFRG9OCmZ4ZXFmRXM4N2c2bDFHQ045SnBXaWZUbmYwU3pQMjE4bGIzdjdWN2F5Um5ncit2V2hMSXNWdzVVRm4rWXNhdmUKZjFUd3k2NmM1Uk5SOFdhREFhL3hLR1BTUkJ2alkxeEVCTmVxOXpPTmlJVDFuN0IvVjhweG84U2k1QkFKbWVhNgp3ZTN6Q3pUalJ0UWN3ZVdEeGJjNG9tL1RmOWE0eVExYTJqMFFwV0J2R1ArQldsc1E5NThodnhvQnBPV1NhM2ExCkErVVdVelBiWUtpN3BkYW1nWFJIU01jV3MwQ3ptOVRiaUF2L2tSNk54VFEwZDU1YzZiTWlPN2xPS251Wmkyd2MKZTdyM1dUNVh5TkNKZUE9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    userTokenSOPS: ZXlKaGJHY2lPaUpTVXpJMU5pSXNJbXRwWkNJNkltRlpkMk40TkdWZmNVUTJhWEZVYjB0MlpsUklXSHBNWVVGUlJrcFNiazl3UW1kM01XbEtSell3WkRBaWZRLmV5SnBjM01pT2lKcmRXSmxjbTVsZEdWekwzTmxjblpwWTJWaFkyTnZkVzUwSWl3aWEzVmlaWEp1WlhSbGN5NXBieTl6WlhKMmFXTmxZV05qYjNWdWRDOXVZVzFsYzNCaFkyVWlPaUp6Y0dGeWF5MWhjSEJzYVdOaGRHbHZibk1pTENKcmRXSmxjbTVsZEdWekxtbHZMM05sY25acFkyVmhZMk52ZFc1MEwzTmxZM0psZEM1dVlXMWxJam9pYkc5allXd3RjM0JoY21zdGIzQmxjbUYwYjNJdGMzQmhjbXN0ZEc5clpXNHRPREp3WW5NaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNXVZVzFsSWpvaWJHOWpZV3d0YzNCaGNtc3RiM0JsY21GMGIzSXRjM0JoY21zaUxDSnJkV0psY201bGRHVnpMbWx2TDNObGNuWnBZMlZoWTJOdmRXNTBMM05sY25acFkyVXRZV05qYjNWdWRDNTFhV1FpT2lJNU16TXhOemhpWXkxaVpUaGlMVFJoWmpZdFlUa3laUzFrTjJZNE9ETXhZVGN3TldJaUxDSnpkV0lpT2lKemVYTjBaVzA2YzJWeWRtbGpaV0ZqWTI5MWJuUTZjM0JoY21zdFlYQndiR2xqWVhScGIyNXpPbXh2WTJGc0xYTndZWEpyTFc5d1pYSmhkRzl5TFhOd1lYSnJJbjAuam9IMWpyZnhWRVg0MkFlUTNLQVdzaWU1LVkwNGRZUm4zMlhGc3M1dGlKRVFmdGhWalUxbmlEcGJZcC03UWlyOGdmNWpZZjRCTDBQNnV1QUdCNzBOM2M5UXZNaTNvTFpCaTdpYXZmMXV5ZHl5WnRKSW9paDVWbUxSenBscXk2Vm1qRkhWLUpLYk1pcWhWd0VVSEhSb0NxRFRNc3Zfb0xPU1p1Ym5tbWxMUlFWR3VRRG5nM2RhVlNpdC03X1hMRWg3VjIzVk1nRExMbnBkWDhlMkxyMjNBdFdKckhjNlBVVk9wSHBuejNINVA3UGxReEh2Rzh4TEhQUy1xOGZhQkhmN2UxZExudk43amFZQlZVOHdSQXZ6U0tyamJIQUVxX3B2LTJPR0pJU21Qczg0dDNUV2tHbzNfbnhtRnNud0IwZFBuRTE4SG1YblhxeF9QdTM5ZVNFVE1R
    userName: spark-operator
    sparkApplicationNamespace: spark-applications
    sparkServiceAccount: local-spark-operator-spark
    sparkVersions:
      - "3.2"
    queues:
      - poc
    ttlSeconds: 259200
    sparkUIUrl: http://localhost:8080
    batchScheduler: yunikorn
    sparkConf:
      spark.kubernetes.executor.podNamePrefix: '{spark-application-resource-name}'
      spark.eventLog.enabled: "true"
      spark.eventLog.dir: s3a://bpg/eventlog
      spark.history.fs.logDirectory: s3a://bpg/eventlog
      spark.sql.warehouse.dir: s3a://bpg/warehouse
      spark.sql.catalogImplementation: hive
      spark.jars.ivy: /opt/spark/work-dir/.ivy2
      spark.hadoop.fs.s3a.connection.ssl.enabled: false
      spark.hadoop.fs.s3a.access.key: claudia_sun
      spark.hadoop.fs.s3a.secret.key: 626b7cde435cf08be6abacdda6e447ca4154ad214d5b628c2b3c103871a9f514
      spark.hadoop.fs.s3a.endpoint: 10.103.216.176:9878
      spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      spark.hadoop.fs.s3a.change.detection.version.required: false
      spark.hadoop.fs.s3a.change.detection.mode: none
      spark.hadoop.fs.s3a.fast.upload: true
      spark.jars.packages: org.apache.hadoop:hadoop-aws:3.2.2
      spark.hadoop.fs.s3a.aws.credentials.provider: org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
    sparkUIOptions:
      ServicePort: 4040
      ingressAnnotations:
        nginx.ingress.kubernetes.io/rewrite-target: /$2
        nginx.ingress.kubernetes.io/proxy-redirect-from: http://$host/
        nginx.ingress.kubernetes.io/proxy-redirect-to: /spark-applications-4/{spark-application-resource-name}/
        kubernetes.io/ingress.class: nginx
        nginx.ingress.kubernetes.io/configuration-snippet: |
          proxy_set_header Accept-Encoding ""; # disable compression
          sub_filter_last_modified off;
          sub_filter '<head>' '<head> <base href="/spark-applications-4/{spark-application-resource-name}/">'; # add base url
          sub_filter 'href="/' 'href="'; # remove absolute URL path so base url applies
          sub_filter 'src="/' 'src="'; # remove absolute URL path so base url applies

          sub_filter '/{{num}}/jobs/' '/jobs/';

          sub_filter "setUIRoot('')" "setUIRoot('/spark-applications-4/{spark-application-resource-name}/')"; # Set UI root for JS scripts
          sub_filter "document.baseURI.split" "document.documentURI.split"; # Executors page issue fix
          sub_filter_once off;
      ingressTLS:
        - hosts:
            - localhost
          secretName: localhost-tls-secret
    driver:
      env:
        - name: STATSD_SERVER_IP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: STATSD_SERVER_PORT
          value: "8125"
    executor:
      env:
        - name: STATSD_SERVER_IP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: STATSD_SERVER_PORT
          value: "8125"
sparkImages:
  - name: apache/spark-py:v3.2.2
    types:
      - Python
    version: "3.2"
  - name: apache/spark:v3.2.2
    types:
      - Java
      - Scala
    version: "3.2"
s3Bucket: bpg
s3Folder: uploaded
sparkLogS3Bucket: bpg
sparkLogIndex: index/index.txt
batchFileLimit: 2016
sparkHistoryDns: localhost
gatewayDns: localhost
sparkHistoryUrl: http://localhost:8088
allowedUsers:
  - '*'
blockedUsers: []
queues:
  - name: poc
    maxRunningMillis: 21600000
queueTokenSOPS: {}
dbStorageSOPS:
  connectionString: jdbc:postgresql://localhost:5432/bpg?useUnicode=yes&characterEncoding=UTF-8&useLegacyDatetimeCode=false&connectTimeout=10000&socketTimeout=30000
  user: bpg
  password: samplepass
statusCacheExpireMillis: 9000
server:
  applicationConnectors:
    - type: http
      port: 8080
logging:
  level: INFO
  loggers:
    com.apple.spark: INFO
sops: {}
